# `E4S0.1 - Time to Live`
### `Alex Petz, Ignite Laboratories, April 2025`

---

Wonderful, now let's change the prior method _slightly_ to inject a "time-to-live" mechanic.

### Self Destruction
Why should a neuron self-destruct?  Well, because without that mechanic the orchestrator would have
to take on management of every single neuron - but they are meant to run _self-contained._  The goal,
as I mentioned before, is _equilibrium_ - that means letting the system naturally spawn more neurons
as necessary _under the assumption_ that they will eventually decay out of the system.  To implement
this is really easy - let's rename the `LoopOnChannel` function and add this functionality - 

    core.engine -

        // LoopXTimes activates the provided action in an asynchronous fashion cyclically, if the potential returns true.
        //
        // This differs from a traditional Loop in that it uses a single goroutine on a channel to activate, rather than
        // creating new goroutines for every activation.
        //
        // 'x' determines how many times the neuron should loop before destroying itself.  Set it to 0 for
        // an infinite looping condition.
        //
        // If 'muted' is true, the neuron is lies dormant until un-muted.
        func (e *Engine) LoopXTimes(action Action, potential Potential, muted bool, x *uint64) *Neuron {
            var n Neuron
            n.ID = NextID()
            n.engine = e

            // KEY: This channel is buffered so senders don't block whilst sending!
            channel := make(chan Context, 128)

            n.Action = func(ctx Context) {
                n.executing = true
                channel <- ctx
            }
            n.Potential = potential
            n.Muted = muted
        
            go func() {
                for ctx := range channel {
                    if n.Destroyed {
                        return
                    }
        
                    action(ctx)
                    n.ActivationCount++
                    n.executing = false
        
			        if *x > 0 && n.ActivationCount >= *x {
                        n.Destroy()
                        return
                    }
                }
            }()
        
            e.addNeuron(&n)
            return &n
        }

Here the neuron will count up to the provided number of cycles before calling its own `Destroy()` method.
This is where we get to begin _logically spawning neurons._  The first structure to handle this kind of
activity is the neural `Cluster` -

    core.cluster -

        type Cluster struct {
	        *Neuron
            Neurons []*Neuron
        }

        func (c *Cluster) Destroy() {
	        c.Neuron.Destroy()
            for _, n := range c.Neurons {
                n.Destroy()
            }
        }

As simple as this structure is, it's quite powerful when leveraged by other structures.  For instance,
if we have a slice of neurons that can be managed we can _cycle_ the neurons through it as a queue of 
similar activations.  Whenever they finish activating they can be placed at the end of the queue.  The 
cluster then can determine on each impulse if the next neuron in the queue is ready to activate - if 
not, it'll spawn a new neuron for that impulse.  

Without a "time-to-live" mechanic built into the neuron, this kind of structure could create an endlessly
long list of goroutines when under extreme load.  Instead, the system will spawn _on demand_ and the
neurons will live as long as necessary before "decaying" out of the queue.

While there is no "structure" to represent different kinds of clusters, there are different ways to
_create_ clusters.  For this solution, I intend to focus on what I call a _cascading cluster._