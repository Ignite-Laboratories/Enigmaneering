# `E1.0 - Quarter Splitting`
## `A.K.A. - "Middle Out Compression"`
### `Alex Petz, Ignite Laboratories, June 2025`

---

### What if you read binary from the top?
Every great project starts with a simple question.  Let's explore this one a bit!

Binary gives us a few unique qualities that most numbers _don't._  For instance, the bit width (which we'll 
call ùëõ) directly defines the absolute largest value that number could _not_ be - 2‚Åø. It also gives us the 
smallest value it _could_ be, 2‚Åø-¬π.

The value exists _between_ those boundaries.

Let's call 2‚Åø-¬π the _light_ value, and (2‚Åø-1) the _dark_ value.

       2‚Åø [ 1 0 0 0 0 0 0 0 0 0 ] (512) <- Upper
     2‚Åø-1   [ 1 1 1 1 1 1 1 1 1 ] (511) <- Dark
            [ 1 1 0 1 0 0 1 0 1 ] (421) <- Target
            [ 1 1 0 0 0 0 0 0 0 ] (384) <- Mid
     2‚Åø-¬π   [ 1 0 0 0 0 0 0 0 0 ] (256) <- Light (or Lower)

The target _clearly_ exists only 37 above the mid point, but we still _store_ it as 421 above _0!_

Why!?

Well, '37' doesn't tell us anything meaningful unless we know _where_ to apply it to.  But we do!
This exists 37 steps _above_ the mid point between the powers of two that bound the target in - and
there are only _four_ different directions we could even walk:

    Up from the lower bound
    Down from the mid point
    Up from the mid point
    Down from the upper bound

Each of those directions represents a _quarter_ of the address space, which is coincidentally _two bits_
of information.  This allows us to start building an encoding scheme:

                   ‚¨ê The remainder bits
    [ ‚Å∞‚ÅÑ‚ÇÅ ‚Å∞‚ÅÑ‚ÇÅ ] [ ‚Å∞‚ÅÑ‚ÇÅ ... ]
         ‚¨ë The focus crumb key
    
    Key | Meaning
     00 | The remainder is read as up from the lower bound
     01 | The remainder is read as down from the mid-point
     10 | The remainder is read as up from the mid-point
     11 | The remainder is read as down from the upper bound

So, let's go back to our previous example and write out the encoded value of 421:

    [ 1 1 0 1 0 0 1 0 1 ] <- Target
    [ 1 0 - 1 0 0 1 0 1 ] <- Encoded

Immediately, we have gained a _single bit_ of reduction!  This is _fantastic_ - but don't start quarter splitting
every byte you find quite yet: _the length has changed_.  Your next measurement would not be readable because you
wouldn't know _when_ it starts!  However, this particular design has an exploit: it works better _at scale_ =)

In fact, this works for literally _any length_ of binary information!  Let's break down what a byte would look like:

    Key | Value Range
     00 | 0-63 (starting from 0)
     01 | 64-127 (starting from 127)
     10 | 128-191 (starting from 128)
     11 | 192-255 (starting from 255)

    [ 0 0 0 0 0 0 0 0 ]   (0) -> [ 0 0 ] (2 bits)
    [ 0 0 0 0 0 1 0 0 ]   (8) -> [ 0 0 - 1 0 0] (5 bits) 
    [ 0 0 1 0 1 0 1 0 ]  (77) -> [ 0 1 - 1 1 0 0 1 1] (8 bits)
    [ 0 1 1 1 1 1 1 1 ] (127) -> [ 0 1 - 1 ] (3 bits)
    [ 1 0 0 0 0 0 0 1 ] (129) -> [ 1 0 - 1 ] (3 bits)
    [ 1 1 0 1 1 1 1 0 ] (222) -> [ 1 1 - 1 0 0 0 1 0 ] (8 bits)
    [ 1 1 1 1 1 1 1 1 ] (255) -> [ 1 1 ] (2 bits)

Lets even break down a _note_ (3 bits):

    Key | Value Range
    00 | 0-1 (starting from 0)
    01 | 2-3 (starting from 3)
    10 | 4-5 (starting from 4)
    11 | 6-7 (starting from 7)

    [ 0 0 0 ] (0) -> [ 0 0 ]
    [ 0 1 0 ] (1) -> [ 0 0 - 1]
    [ 0 0 1 ] (2) -> [ 0 1 ]
    [ 0 1 1 ] (3) -> [ 0 1 - 1 ]
    [ 1 0 0 ] (4) -> [ 1 0 ]
    [ 1 0 1 ] (5) -> [ 1 0 - 1 ]
    [ 1 1 0 ] (6) -> [ 1 1 ]
    [ 1 1 1 ] (7) -> [ 1 1 - 1 ]

The first thing you'll notice is that key `01` starts at -1 from the mid point, which allows full coverage
of the range while including '0' as an addressable value.

### Recursion
As I said before, this applies to binary information _at any scale._  However, at the astronomical scales that
a _file_ exists at - the amount of bits that reduces from each operation is _significantly_ more beneficial.
To take advantage of this paradigm, however, we get to turn to my favorite topic: _recursion!_

I know, I know, it's the bane of many a programmer's existence - but it truly is beauty in motion, when
built well. Some of the best examples of computational efficiency evolved from recursive algorithms, and
I absolutely adore the amount of ingenuity it took for those enigmaneers to craft them.

So, let's now look at the _downside_ of binary information:

Logical binary information allows leading 0s

Numerical binary information does _not_

Let me explain - the first _byte_ of a file might start with several zeros, which is perfectly reasonable
in that context.  However, when the value converts to a _numeric_ form those zeros are simply _lost!_ This
will need more addressing, later on, but it's important to _consider_ right now.  To get around this, we
will do several very important things:

- The key information will always be on the _left_
- Each transformation round will be considered a 'movement' of binary information
- The very first bit of any movement is the 'terminus' bit, which always holds a value of '1'
- A 'recycle' bit in the key should indicate if the process synthesis should continue after this round completes
- The process of shrinking binary information is 'distilling'
- The process of growing binary information is 'synthesizing'

This means our abstract movement structure looks like this:

    Abstract Movement Encoding:

           ‚¨ê Recycle Bit    ‚¨ê Value
    [ 1 - ‚Å∞‚ÅÑ‚ÇÅ - ‚Å∞‚ÅÑ‚ÇÅ ‚Å∞‚ÅÑ‚ÇÅ ] [ ‚Å∞‚ÅÑ‚ÇÅ ... ]
      ‚¨ë Terminus   ‚¨ë Focus Crumb

The first phrase is the _key,_ while the second is the _value_ and holds the actual data to encode.

Now, the one major point you've probably got in your mind is this: by prepending the data with bits, it will
sometimes grow _larger_ than the target bit width! And you'd be right!  However, it would only happen
when the value to encode is a perfect distance from the boundary point - which diminishes in likelihood significantly
_at scale._  That being said, even if it _did_ grow during the distillation process it would then move it into a
new value position that is not sympathetic to the failure point - thus, it wouldn't _loop_ and you'd likely never
even notice when it occurs.

The recycle bit would be set to 0 during the first movement, and then 1 on any following movement.  When synthesizing
the value, this would signal that the final transformation should _not_ be read as an encoded value.  Instead it
represents the final form the data should be placed within.

The _only_ part this scheme does not yet encode is the amount of zeros to prepend to the data when the synthesis
process completes. This can also be accomplished on the _first_ movement by injecting a _metadata_ phrase between
the key and value:

    Initial Movement Encoding:

          ‚¨ê Recycle Bit    ‚¨ê Metadata
    [ 1 - 0 - ‚Å∞‚ÅÑ‚ÇÅ ‚Å∞‚ÅÑ‚ÇÅ ] [ ‚Å∞‚ÅÑ‚ÇÅ ... ] [ ‚Å∞‚ÅÑ‚ÇÅ ... ]
      ‚¨ë Terminus ‚¨ë Focus Crumb        ‚¨ë Value

    Subsequent Movement Encoding:

          ‚¨ê Recycle Bit    ‚¨ê Metadata
    [ 1 - 1 - ‚Å∞‚ÅÑ‚ÇÅ ‚Å∞‚ÅÑ‚ÇÅ ] [ ‚Å∞‚ÅÑ‚ÇÅ ... ]
      ‚¨ë Terminus ‚¨ë Focus Crumb

Now, the million dollar question that remains: _when do you stop distilling?_

That's easy: when you can no longer shrink the data by _prepending_ the encoding scheme data.  Every single
movement requires _adding_ data to the current bits, which means eventually the process would not allow your
data to shrink any further.  When I hit that boundary, I'll add further to this =)